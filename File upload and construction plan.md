ä»¥ä¸‹æ˜¯ **GitHub äº‘ç›˜æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½çš„å®Œæ•´å®ç°æ–¹æ¡ˆ**ï¼ŒåŒ…å«å‰ç«¯åŠ å¯†ã€åˆ†ç‰‡ä¸Šä¼ ã€åç«¯éªŒè¯ç­‰å…¨æµç¨‹æŠ€æœ¯ç»†èŠ‚ï¼š

---

### ğŸš€ **å…¨åŠŸèƒ½ä¸Šä¼ ç³»ç»Ÿæ¶æ„**
```mermaid
sequenceDiagram
    participant ç”¨æˆ·ç«¯
    participant å‰ç«¯åŠ å¯†
    participant åˆ†ç‰‡ä¸Šä¼ 
    participant GitHubAPI
    participant åç«¯éªŒè¯
    
    ç”¨æˆ·ç«¯->>å‰ç«¯åŠ å¯†: é€‰æ‹©æ–‡ä»¶(1GBè§†é¢‘.mp4)
    å‰ç«¯åŠ å¯†->>åˆ†ç‰‡ä¸Šä¼ : åˆ†ç‰‡(æ¯ç‰‡5MB)+AES-256åŠ å¯†
    åˆ†ç‰‡ä¸Šä¼ ->>GitHubAPI: å¹¶è¡Œä¸Šä¼ åˆ†ç‰‡(part1.enc~part200.enc)
    GitHubAPI-->>åç«¯éªŒè¯: è¿”å›åˆ†ç‰‡å“ˆå¸Œ
    åç«¯éªŒè¯->>GitHubAPI: éªŒè¯ååˆå¹¶æ–‡ä»¶
    GitHubAPI-->>ç”¨æˆ·ç«¯: è¿”å›å®Œæ•´æ–‡ä»¶URL
```

---

### 1. **å‰ç«¯åŠ å¯†ä¸Šä¼ å®ç°**
#### 1.1 æ ¸å¿ƒä»£ç  (`uploader.js`)
```javascript
class SecureUploader {
  constructor(token) {
    this.token = token;
    this.CHUNK_SIZE = 5 * 1024 * 1024; // 5MBåˆ†ç‰‡
    this.MAX_RETRY = 3;
  }

  async upload(file, { onProgress, onEncrypt }) {
    // 1. ç”Ÿæˆæ–‡ä»¶å”¯ä¸€æ ‡è¯†
    const fileKey = await this._generateFileKey(file);
    const chunkCount = Math.ceil(file.size / this.CHUNK_SIZE);
    
    // 2. åˆ›å»ºä¸Šä¼ ä¼šè¯
    const sessionId = await this._createUploadSession({
      fileName: file.name,
      fileSize: file.size,
      chunkCount,
      fileKey
    });

    // 3. åˆ†ç‰‡åŠ å¯†ä¸Šä¼ 
    for (let i = 0; i < chunkCount; i++) {
      let retry = 0;
      while (retry < this.MAX_RETRY) {
        try {
          const chunk = file.slice(i * this.CHUNK_SIZE, (i + 1) * this.CHUNK_SIZE);
          const { encrypted, iv } = await this._encryptChunk(chunk, await onEncrypt());
          
          await this._uploadChunk({
            sessionId,
            chunk: encrypted,
            index: i,
            iv,
            fileKey
          });
          
          onProgress((i + 1) / chunkCount * 100);
          break;
        } catch (error) {
          if (++retry === this.MAX_RETRY) throw error;
        }
      }
    }

    // 4. å®Œæˆä¸Šä¼ 
    return this._finalizeUpload(sessionId, file.name);
  }

  async _encryptChunk(chunk, password) {
    const iv = crypto.getRandomValues(new Uint8Array(12));
    const salt = crypto.getRandomValues(new Uint8Array(16));
    
    // å¯†é’¥æ´¾ç”Ÿ
    const keyMaterial = await crypto.subtle.importKey(
      "raw",
      new TextEncoder().encode(password),
      "PBKDF2",
      false,
      ["deriveKey"]
    );
    
    const key = await crypto.subtle.deriveKey(
      {
        name: "PBKDF2",
        salt,
        iterations: 100000,
        hash: "SHA-256"
      },
      keyMaterial,
      { name: "AES-GCM", length: 256 },
      false,
      ["encrypt"]
    );

    // åŠ å¯†åˆ†ç‰‡
    const encrypted = await crypto.subtle.encrypt(
      { name: "AES-GCM", iv },
      key,
      await chunk.arrayBuffer()
    );

    return {
      encrypted: new Uint8Array(encrypted),
      iv: Array.from(iv),
      salt: Array.from(salt)
    };
  }
}
```

#### 1.2 è°ƒç”¨ç¤ºä¾‹
```javascript
// å‰ç«¯é¡µé¢è°ƒç”¨
const uploader = new SecureUploader('ghp_your_token_here');

document.getElementById('upload-btn').addEventListener('click', async () => {
  const file = document.getElementById('file-input').files[0];
  
  try {
    await uploader.upload(file, {
      onProgress: (percent) => {
        console.log(`ä¸Šä¼ è¿›åº¦: ${percent.toFixed(1)}%`);
        progressBar.style.width = `${percent}%`;
      },
      onEncrypt: () => {
        return prompt('è¯·è¾“å…¥æ–‡ä»¶åŠ å¯†å¯†ç :'); // å®é™…åº”ç”¨åº”ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼è·å–å¯†ç 
      }
    });
    
    alert('æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼');
  } catch (error) {
    console.error('ä¸Šä¼ å¤±è´¥:', error);
    alert(`ä¸Šä¼ å¤±è´¥: ${error.message}`);
  }
});
```

---

### 2. **åç«¯éªŒè¯ä¸åˆå¹¶**
#### 2.1 GitHub Actions å·¥ä½œæµ (`.github/workflows/merge_chunks.yml`)
```yaml
name: Merge Uploaded Chunks
on:
  repository_dispatch:
    types: [merge_request]

jobs:
  merge:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Download all chunks
        run: |
          mkdir -p chunks
          gh api /repos/${{ github.repository }}/contents/uploads \
            --jq '.[] | select(.name | endswith(".enc")) | .download_url' \
            | xargs -n1 wget -P chunks/
            
      - name: Decrypt and merge
        env:
          DECRYPT_KEY: ${{ secrets.DECRYPT_KEY }}
        run: |
          # æŒ‰åˆ†ç‰‡ç¼–å·æ’åº
          ls chunks/*.enc | sort -t_ -k2 -n > chunk_list.txt
          
          # åˆå¹¶æ–‡ä»¶
          while read -r chunk; do
            openssl enc -d -aes-256-gcm -iv $(cat ${chunk}.iv) \
              -K $DECRYPT_KEY -in $chunk >> merged_file
          done < chunk_list.txt
          
      - name: Upload final file
        run: |
          gh api -X PUT /repos/${{ github.repository }}/contents/files/merged_file \
            -H "Authorization: Bearer ${{ secrets.GH_TOKEN }}" \
            -F message="Merged file" \
            -F content="$(base64 -w0 merged_file)"
```

#### 2.2 åˆ†ç‰‡éªŒè¯è„šæœ¬
```python
# verify_chunks.py
import hashlib
from pathlib import Path

def verify_chunks(chunk_dir: Path, expected_hashes: dict):
    bad_chunks = []
    
    for chunk_file in chunk_dir.glob("*.enc"):
        chunk_hash = hashlib.sha256(chunk_file.read_bytes()).hexdigest()
        if chunk_hash != expected_hashes[chunk_file.name]:
            bad_chunks.append(chunk_file.name)
    
    if bad_chunks:
        raise ValueError(f"æ ¡éªŒå¤±è´¥çš„åˆ†ç‰‡: {bad_chunks}")
    print("æ‰€æœ‰åˆ†ç‰‡éªŒè¯é€šè¿‡")
```

---

### 3. **é«˜çº§åŠŸèƒ½æ‰©å±•**
#### 3.1 æ–­ç‚¹ç»­ä¼ å®ç°
```javascript
// uploader.js æ–°å¢æ–¹æ³•
class SecureUploader {
  // ...åŸæœ‰ä»£ç ...

  async resumeUpload(sessionId) {
    // 1. è·å–å·²ä¸Šä¼ åˆ†ç‰‡ä¿¡æ¯
    const { uploadedChunks, fileInfo } = await this._getUploadStatus(sessionId);
    
    // 2. ç»§ç»­ä¸Šä¼ å‰©ä½™åˆ†ç‰‡
    const file = await this._getFileFromCache(fileInfo.fileKey);
    for (let i = 0; i < fileInfo.chunkCount; i++) {
      if (uploadedChunks.includes(i)) continue;
      
      // ...åˆ†ç‰‡ä¸Šä¼ é€»è¾‘...
    }
  }

  async _getFileFromCache(fileKey) {
    return new Promise((resolve) => {
      caches.match(`/file_cache/${fileKey}`).then(response => {
        if (response) return response.blob();
        throw new Error("æœ¬åœ°ç¼“å­˜å·²å¤±æ•ˆ");
      });
    });
  }
}
```

#### 3.2 æµè§ˆå™¨ç«¯ç¼“å­˜ç®¡ç†
```javascript
// ä¸Šä¼ å‰ç¼“å­˜æ–‡ä»¶
async function cacheFile(file) {
  const cache = await caches.open('file_uploads');
  const fileKey = generateFileKey(file.name);
  await cache.put(
    new Request(`/file_cache/${fileKey}`),
    new Response(file)
  );
  return fileKey;
}

// æ³¨å†ŒService Worker
if ('serviceWorker' in navigator) {
  navigator.serviceWorker.register('/sw.js', {
    scope: '/file_cache/'
  });
}
```

---

### 4. **å®‰å…¨é˜²æŠ¤æªæ–½**
#### 4.1 ä¸Šä¼ é™åˆ¶ç­–ç•¥
```nginx
# Nginx é…ç½®
http {
    client_max_body_size 10G;  # å…è®¸æœ€å¤§10GBæ–‡ä»¶
    client_body_temp_path /tmp/nginx_upload;
    
    server {
        location /upload {
            # é™åˆ¶ä¸Šä¼ é€Ÿç‡
            limit_rate 10m;  # æ¯ç§’10MB
            
            # æ–‡ä»¶ç±»å‹æ£€æŸ¥
            if ($request_filename ~* \.(php|exe)$) {
                return 403;
            }
        }
    }
}
```

#### 4.2 ç—…æ¯’æ‰«æé›†æˆ
```yaml
# GitHub Actions ç—…æ¯’æ‰«æ
- name: Virus Scan
  uses: actions/virus-scan@v1
  with:
    path: merged_file
    clamav: true
    fail-on-virus: true
```

---

### 5. **æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ**
#### 5.1 å¹¶è¡Œä¸Šä¼ åŠ é€Ÿ
```javascript
// ä¿®æ”¹ä¸Šä¼ é€»è¾‘ä¸ºå¹¶è¡Œ
async _uploadAllChunks(chunks) {
  const CONCURRENCY = 4; // å¹¶è¡Œæ•°
  const queue = [];
  
  for (let i = 0; i < chunks.length; i += CONCURRENCY) {
    const batch = chunks.slice(i, i + CONCURRENCY);
    queue.push(Promise.all(batch.map(chunk => this._uploadChunk(chunk))));
    
    // æ§åˆ¶å†…å­˜ä½¿ç”¨
    if (queue.length >= 3) {
      await queue.shift();
    }
  }
  
  await Promise.all(queue);
}
```

#### 5.2 å†…å­˜ä¼˜åŒ–æŠ€å·§
```javascript
// ä½¿ç”¨æµå¼è¯»å–å¤§æ–‡ä»¶
async function* chunkGenerator(file, chunkSize) {
  let offset = 0;
  const buffer = new Uint8Array(chunkSize);
  
  while (offset < file.size) {
    const slice = file.slice(offset, offset + chunkSize);
    const chunkBuffer = await slice.arrayBuffer();
    buffer.set(new Uint8Array(chunkBuffer), 0);
    yield buffer.subarray(0, chunkBuffer.byteLength);
    offset += chunkSize;
  }
}

// ä½¿ç”¨ç¤ºä¾‹
for await (const chunk of chunkGenerator(bigFile, 5 * 1024 * 1024)) {
  await uploadChunk(chunk);
}
```

---

### ğŸ›  **å®Œæ•´éƒ¨ç½²æµç¨‹**
1. **å‰ç«¯éƒ¨ç½²**
```bash
npm install
npm run build
gh-pages -d dist -b gh-pages
```

2. **åç«¯æœåŠ¡éƒ¨ç½²**
```bash
# ä½¿ç”¨ Vercel éƒ¨ç½²ä»£ç†æœåŠ¡å™¨
vc --prod --token=$VERCEL_TOKEN
```

3. **GitHub é…ç½®**
```bash
# è®¾ç½®ä»“åº“ Secrets
gh secret set GH_TOKEN --body="ghp_your_token"
gh secret set DECRYPT_KEY --body="your_encryption_key"
```

---

### âš ï¸ **å…³é”®æ³¨æ„äº‹é¡¹**
1. **å¯†é’¥ç®¡ç†**ï¼š
   - æ°¸è¿œä¸è¦åœ¨å‰ç«¯ä»£ç ç¡¬ç¼–ç  Token
   - ä½¿ç”¨ GitHub Secrets å­˜å‚¨æ•æ„Ÿä¿¡æ¯
   - å®šæœŸè½®æ¢åŠ å¯†å¯†é’¥

2. **é”™è¯¯æ¢å¤**ï¼š
   ```javascript
   // å®ç°è‡ªåŠ¨é‡è¯•æœºåˆ¶
   async _uploadWithRetry(chunk, retries = 3) {
     try {
       return await this._uploadChunk(chunk);
     } catch (error) {
       if (retries <= 0) throw error;
       await new Promise(r => setTimeout(r, 1000 * (4 - retries)));
       return this._uploadWithRetry(chunk, retries - 1);
     }
   }
   ```

3. **æµè§ˆå™¨å…¼å®¹æ€§**ï¼š
   ```html
   <!-- æ·»åŠ  polyfill -->
   <script src="https://cdn.jsdelivr.net/npm/@peculiar/webcrypto@2.3.3/dist/webcrypto.min.js"></script>
   <script>
     if (!window.crypto) window.crypto = new PeculiarWebCrypto.WebCrypto();
   </script>
   ```

---

# ä»¥ä¸Šæ–¹æ¡ˆå®ç°äº†ä¼ä¸šçº§å®‰å…¨æ–‡ä»¶ä¸Šä¼ æ‰€éœ€çš„æ‰€æœ‰åŠŸèƒ½ç»„ä»¶,è‡³æ­¤ï¼Œä½ å·²ç»ä¼šè¿›è¡Œå®Œæ•´ä¸Šä¼ æ“ä½œ
